{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXydnLO1siFMDNvifRFDCV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spidey03/digit_recognition/blob/main/digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swn8sExTKKln"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH-gaMj7OyOo",
        "outputId": "e3e4f994-0f8a-4a44-9f8b-e9e003fca5bb"
      },
      "source": [
        "! wget https://myawsbucket003.s3.ap-south-1.amazonaws.com/AI+ML/Digit+Recognition/datasets/mnist_test.csv\n",
        "! wget https://myawsbucket003.s3.ap-south-1.amazonaws.com/AI+ML/Digit+Recognition/datasets/mnist_train.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-09 07:49:06--  https://myawsbucket003.s3.ap-south-1.amazonaws.com/AI+ML/Digit+Recognition/datasets/mnist_test.csv\n",
            "Resolving myawsbucket003.s3.ap-south-1.amazonaws.com (myawsbucket003.s3.ap-south-1.amazonaws.com)... 52.219.66.111\n",
            "Connecting to myawsbucket003.s3.ap-south-1.amazonaws.com (myawsbucket003.s3.ap-south-1.amazonaws.com)|52.219.66.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18289443 (17M) [text/csv]\n",
            "Saving to: ‘mnist_test.csv.1’\n",
            "\n",
            "mnist_test.csv.1    100%[===================>]  17.44M  5.84MB/s    in 3.0s    \n",
            "\n",
            "2021-07-09 07:49:10 (5.84 MB/s) - ‘mnist_test.csv.1’ saved [18289443/18289443]\n",
            "\n",
            "--2021-07-09 07:49:10--  https://myawsbucket003.s3.ap-south-1.amazonaws.com/AI+ML/Digit+Recognition/datasets/mnist_train.csv\n",
            "Resolving myawsbucket003.s3.ap-south-1.amazonaws.com (myawsbucket003.s3.ap-south-1.amazonaws.com)... 52.219.64.19\n",
            "Connecting to myawsbucket003.s3.ap-south-1.amazonaws.com (myawsbucket003.s3.ap-south-1.amazonaws.com)|52.219.64.19|:443... connected.\n",
            "HTTP request sent, awaiting response... ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrNvqRUTKw1U"
      },
      "source": [
        "class HandWritterDigitRecognition:\n",
        "    def __init__(self):\n",
        "        self.train_data_file = \"mnist_train.csv\"\n",
        "        self.test_data_file = \"mnist_test.csv\"\n",
        "\n",
        "    def get_data_from_train_data_file(self):\n",
        "        data = np.genfromtxt(\n",
        "            fname=self.train_data_file, delimiter=\",\", dtype=int\n",
        "        )\n",
        "        print(\"Shape of data in train data file is {}\".format(data.shape))\n",
        "        mnist_labels = data[:, 0]\n",
        "        mnist_variables = data[:, 1:]\n",
        "        return mnist_variables, mnist_labels\n",
        "\n",
        "    @staticmethod\n",
        "    def shuffle(variables, labels):\n",
        "        data_count = variables.shape[0]\n",
        "        np.random.seed(3)\n",
        "        permute_indices = np.random.permutation(data_count)\n",
        "        shuffled_variables = variables[permute_indices]\n",
        "        shuffled_labels = labels[permute_indices]\n",
        "        return shuffled_variables, shuffled_labels\n",
        "\n",
        "    def get_best_k_n_values_using_validation_set(\n",
        "            self, variables, labels, validation_split_percent, possible_values_of_n\n",
        "    ):\n",
        "        import math\n",
        "        shuffled_variables, shuffled_labels = \\\n",
        "            self.shuffle(variables=variables, labels=labels)\n",
        "        train_data_count = math.floor(\n",
        "            (float(100 - validation_split_percent) / 100) * variables.shape[0]\n",
        "        )\n",
        "        train_inputs = shuffled_variables[:train_data_count]\n",
        "        train_outputs = shuffled_labels[:train_data_count]\n",
        "        validation_inputs = shuffled_variables[train_data_count:]\n",
        "        validation_outputs = shuffled_labels[train_data_count:]\n",
        "\n",
        "        accuracy_matrix = np.empty(shape=(possible_values_of_n.shape[0], train_data_count))\n",
        "        for n_idx, n in enumerate(possible_values_of_n):\n",
        "            for k_idx, k in enumerate(range(1, train_data_count+1)):\n",
        "                predicted_labels = self.majority_based_knn(\n",
        "                    train_inputs=train_inputs, train_outputs=train_outputs,\n",
        "                    test_inputs=validation_inputs, n=n, k=k\n",
        "                )\n",
        "                accuracy = self.calculate_accuracy(\n",
        "                    predicted_labels=predicted_labels,\n",
        "                    actual_labels=validation_outputs\n",
        "                )\n",
        "                accuracy_matrix[n_idx][k_idx] = accuracy\n",
        "\n",
        "        max_accuracy = np.max(accuracy_matrix)\n",
        "        ties = (accuracy_matrix == max_accuracy)\n",
        "\n",
        "        n_idx = np.argmax(np.any(ties, axis=1))\n",
        "        n = possible_values_of_n[n_idx]\n",
        "        k = np.argmax(ties[n_idx, :]) + 1\n",
        "        return np.array([k, n], dtype=int)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_accuracy(predicted_labels, actual_labels):\n",
        "        true_predictions = np.count_nonzero(predicted_labels==actual_labels)\n",
        "        accuracy = (true_predictions/actual_labels.size)\n",
        "        return accuracy\n",
        "\n",
        "    def majority_based_knn(self, train_inputs, train_outputs, test_inputs, n, k):\n",
        "        \"\"\"\n",
        "        predict the label for test inputs based on the majority among K nearest neighbours\n",
        "\n",
        "        :param train_inputs: a 2D numpy array of floats where each row represents a training input instance\n",
        "        :param train_outputs: a 2D numpy array that represents the labels corresponds to train_inputs\n",
        "        :param test_inputs: a 2D numpy array of floats which represent training instances\n",
        "        :param n: n is for compute LN Norm distance\n",
        "        :param k: k is the number of closest neighbours to consider\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        unique_class_labels = np.unique(train_outputs)\n",
        "        num_of_unique_class_labels = unique_class_labels.shape[0]\n",
        "\n",
        "        label_wise_counts = np.zeros(shape=(test_inputs.shape[0], num_of_unique_class_labels))\n",
        "        label_wise_weights = np.zeros(shape=(test_inputs.shape[0], num_of_unique_class_labels))\n",
        "\n",
        "        for test_idx, test_input in enumerate(test_inputs):\n",
        "            k_distance_indices, k_distances = self.k_nearest_neightbours(\n",
        "                train_inputs=train_inputs, test_input=test_input, n=n, k=k\n",
        "            )\n",
        "            predicted_labels = train_outputs[k_distance_indices]\n",
        "            for label_idx, label in enumerate(unique_class_labels):\n",
        "                label_weight = np.sum(np.where(predicted_labels == label, 1/k_distances, 0.0))\n",
        "                label_count = np.sum(np.where(predicted_labels == label, 1.0, 0.0))\n",
        "                label_wise_weights[test_idx][label_idx] = label_weight\n",
        "                label_wise_counts[test_idx][label_idx] = label_count\n",
        "\n",
        "        output_labels = np.empty(test_inputs.shape[0], dtype=int)\n",
        "        sorted_count_indices = np.argsort(label_wise_counts, axis=1)\n",
        "\n",
        "        for test_idx, label_indices in enumerate(sorted_count_indices):\n",
        "            highest_count = label_wise_counts[test_idx][label_indices[num_of_unique_class_labels-1]]\n",
        "            highest_label_repeat = np.count_nonzero(label_wise_counts[test_idx] == highest_count)\n",
        "            no_voting_tie = (highest_label_repeat == 1)\n",
        "            if no_voting_tie:\n",
        "                output_labels[test_idx] = unique_class_labels[label_indices[num_of_unique_class_labels-1]]\n",
        "            else:\n",
        "                tied_class_indices = label_indices[num_of_unique_class_labels-highest_label_repeat:]\n",
        "                tied_class_weights = label_wise_weights[test_idx][tied_class_indices]\n",
        "                max_weight_idx = np.argmax(tied_class_weights)\n",
        "                max_idx = tied_class_indices[max_weight_idx]\n",
        "                output_labels[test_idx] = unique_class_labels[max_idx]\n",
        "\n",
        "        return output_labels\n",
        "\n",
        "    def distance_weighted_knn(self, train_inputs, train_outputs, test_inputs, n, k):\n",
        "        \"\"\"\n",
        "        Predict the label using distance weighted KNN\n",
        "\n",
        "        :param train_inputs: a 2D numpy array of floats where each row represents a training input instance\n",
        "        :param train_outputs: a 2D numpy array that represents the labels corresponds to train_inputs\n",
        "        :param test_inputs: a 2D numpy array of floats which represent training instances\n",
        "        :param n: n is for compute LN Norm distance\n",
        "        :param k: k is the number of closest neighbours to consider\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        unique_class_labels = np.unique(train_outputs)\n",
        "        weights = np.zeros(shape=(train_inputs.shape[0], unique_class_labels.shape[0]))\n",
        "        for test_idx, test_input in enumerate(test_inputs):\n",
        "            k_distance_indices, k_distances = self.k_nearest_neightbours(\n",
        "                train_inputs=train_inputs, test_input=test_input, n=n, k=k\n",
        "            )\n",
        "            predicted_labels = train_outputs[k_distance_indices]\n",
        "            for label_idx, label in enumerate(unique_class_labels):\n",
        "                label_weight = np.sum(np.where(predicted_labels == label, 1/k_distances, 0.0))\n",
        "                weights[test_idx][label_idx] = label_weight\n",
        "\n",
        "        highest_label_indices = np.argmax(weights, axis=1)\n",
        "        return unique_class_labels[highest_label_indices]\n",
        "\n",
        "    def k_nearest_neightbours(self, train_inputs, test_input, n, k):\n",
        "        \"\"\"\n",
        "        Get K nearest neighbours of the test inputs\n",
        "\n",
        "        :param train_inputs: a 2D numpy array of floats where each row represents a training input instance\n",
        "        :param test_input: a 1D numpy array of floats which represent training instance\n",
        "        :param n: n is for compute LN Norm distance\n",
        "        :param k: k is the number of closest neighbours to consider\n",
        "        :return: returns indices of K-nearest neighbours and their distances\n",
        "        \"\"\"\n",
        "        distances = self.ln_norm_distances(\n",
        "            train_inputs=train_inputs, test_input=test_input, n=n\n",
        "        )\n",
        "        indices = np.argsort(distances)\n",
        "        kth_dist_repeat_count = 0\n",
        "        if train_inputs.shape[0] > k:\n",
        "            kth_nearesh_neighbour_index = indices[k - 1]  # last most neighbour\n",
        "            kth_neighbour_distance = distances[kth_nearesh_neighbour_index]\n",
        "            indices_except_top_k = indices[k:]\n",
        "            # distance tie\n",
        "            distance_of_points_except_top_k = distances[indices_except_top_k]\n",
        "            kth_dist_repeat_count = np.count_nonzero(distance_of_points_except_top_k == kth_neighbour_distance)\n",
        "        indices_of_k_neighbours = indices[:(k+kth_dist_repeat_count)]\n",
        "        distance_k = distances[indices_of_k_neighbours]\n",
        "        return indices_of_k_neighbours, distance_k\n",
        "\n",
        "    @staticmethod\n",
        "    def ln_norm_distances(train_inputs, test_input, n):\n",
        "        \"\"\"\n",
        "        LN Norm Distances which computes distances between\n",
        "        a testing instance and other training instance\n",
        "\n",
        "        :param train_inputs: a 2D numpy array of floats where each row represents a training input instance\n",
        "        :param test_input: a 1D numpy array of floats which represent training instance\n",
        "        :param n: n is for compute LN Norm distance\n",
        "        :return: a 1D of array floats i.e distance between testing instance and trainging instances\n",
        "        \"\"\"\n",
        "        abs_diff = np.abs(train_inputs - test_input)\n",
        "        summation = np.sum(np.power(abs_diff, n), axis=1)\n",
        "        return np.power(summation, 1 / n)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoI4GZOeQIJ9"
      },
      "source": [
        "digit_recognition = HandWritterDigitRecognition()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRXxkIF3RF8I",
        "outputId": "b653927b-b8c0-4000-871c-0ba9ef170feb"
      },
      "source": [
        "variables, labels = digit_recognition.get_data_from_train_data_file()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data in train data file is (60000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6B5o-U2K0wO"
      },
      "source": [
        "validation_split_percent = 30\n",
        "n = np.array([1, 2, 3])\n",
        "best_k_n = digit_recognition.get_best_k_n_values_using_validation_set(\n",
        "    variables=variables, labels=labels.reshape(-1,),\n",
        "    validation_split_percent=validation_split_percent,\n",
        "    possible_values_of_n=n\n",
        ")\n",
        "print(best_k_n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdnpTv_APbNg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}